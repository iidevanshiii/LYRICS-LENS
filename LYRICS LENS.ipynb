{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c1dc38-15fc-47bf-9d6f-2d9ae04b4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set. Data dir: ./lyrics_lens_data/delta_tables\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import os\n",
    "DATA_DIR = './lyrics_lens_data'\n",
    "DELTA_DIR = os.path.join(DATA_DIR, 'delta_tables')\n",
    "os.makedirs(DELTA_DIR, exist_ok=True)\n",
    "\n",
    "MAX_SCRAPED_RECORDS = 100\n",
    "REQUEST_SLEEP = (1.0, 2.0)  # polite delays (seconds)\n",
    "SEED_QUERIES = [\n",
    "    \"Adele Hello\", \"Ed Sheeran Shape of You\", \"Billie Eilish bad guy\", \"Coldplay Yellow\", \"Taylor Swift Love Story\",\n",
    "    \"Drake Hotline Bling\", \"The Weeknd Blinding Lights\", \"Bruno Mars Uptown Funk\"\n",
    "]\n",
    "print('Configuration set. Data dir:', DELTA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31efef85-304c-4b60-8c7f-d6f891cf4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected:  - D’Elmar Zaya\n",
      "Collected:  - Bis Hierhin\n",
      "Collected:  - Losin’ Streak\n",
      "Collected:  - Love in a Bottle\n",
      "Collected:  - VOX POPULI\n",
      "Total songs collected: 5\n"
     ]
    }
   ],
   "source": [
    "# Genius scraper (HTML-based, direct requests, polite delays)\n",
    "# NOTE: Respect robots.txt and terms of service. This is educational for capstone use.\n",
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_request_simple(url, timeout=15):\n",
    "    headers = {'User-Agent': 'LyricsLensBot/1.0 (+https://example.com)'}\n",
    "    r = requests.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def genius_search_results(query):\n",
    "    base = \"https://genius.com\"\n",
    "    search_url = f\"{base}/search?q={requests.utils.quote(query)}\"\n",
    "    html = get_request_simple(search_url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = []\n",
    "    for a in soup.select(\"a.mini_card\"):\n",
    "        href = a.get('href')\n",
    "        if href and href.startswith(base):\n",
    "            links.append(href)\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        href = a.get('href')\n",
    "        if href and href.startswith(base) and href.endswith(\"-lyrics\"):\n",
    "            links.append(href)\n",
    "    seen = set(); out = []\n",
    "    for l in links:\n",
    "        if l not in seen:\n",
    "            seen.add(l); out.append(l)\n",
    "    return out\n",
    "\n",
    "def scrape_genius_song(url):\n",
    "    html = get_request_simple(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    title_tag = soup.find(\"h1\", {\"class\": \"header_with_cover_art-primary_info-title\"})\n",
    "    if not title_tag:\n",
    "        title_tag = soup.find(\"h1\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "    artist_tag = soup.select_one(\"a.header_with_cover_art-primary_info-primary_artist\")\n",
    "    artist = artist_tag.get_text(strip=True) if artist_tag else \"\"\n",
    "    lyrics_containers = soup.select(\"div[data-lyrics-container='true']\")\n",
    "    if lyrics_containers:\n",
    "        lyrics = \"\\n\".join([c.get_text(separator=\"\\n\").strip() for c in lyrics_containers])\n",
    "    else:\n",
    "        dug = soup.find(\"div\", class_=\"lyrics\")\n",
    "        if dug:\n",
    "            lyrics = dug.get_text(separator=\"\\n\").strip()\n",
    "        else:\n",
    "            divs = soup.find_all(\"div\")\n",
    "            lyrics = max(divs, key=lambda d: len(d.get_text())).get_text(separator=\"\\n\").strip() if divs else \"\"\n",
    "    return {\"artist\": artist, \"title\": title, \"lyrics\": lyrics, \"url\": url}\n",
    "\n",
    "# Collect songs (up to MAX_SCRAPED_RECORDS)\n",
    "collected = []\n",
    "visited = set()\n",
    "for q in SEED_QUERIES:\n",
    "    if len(collected) >= MAX_SCRAPED_RECORDS: break\n",
    "    try:\n",
    "        results = genius_search_results(q)\n",
    "    except Exception as e:\n",
    "        print('Search failed for', q, e); continue\n",
    "    for url in results:\n",
    "        if len(collected) >= MAX_SCRAPED_RECORDS: break\n",
    "        if url in visited: continue\n",
    "        try:\n",
    "            time.sleep(random.uniform(*REQUEST_SLEEP))\n",
    "            song = scrape_genius_song(url)\n",
    "            if song and song.get('lyrics'):\n",
    "                collected.append(song); visited.add(url)\n",
    "                print('Collected:', song['artist'], '-', song['title'])\n",
    "        except Exception as e:\n",
    "            print('Failed:', url, e); continue\n",
    "\n",
    "songs_df = pd.DataFrame(collected)\n",
    "print('Total songs collected:', len(songs_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c38cfb5-8630-43ca-8996-6c04233b081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing: clean lyrics, tokenize, lemmatize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2119a3f-8edf-40ce-8c84-2d0c09140e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/devanshisharma/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- Text Preprocessing Function ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required resources (safe to run multiple times)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean, tokenize, remove stopwords, and lemmatize the input lyrics.\n",
    "    Returns a processed string ready for NLP tasks.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"\"\n",
    "    text = text.replace('\\r', ' ').replace('\\n', ' ').lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f55cb7-b89a-4677-9f51-9f6e886dd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df['clean_lyrics'] = songs_df['lyrics'].fillna('').apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "371c1a86-4502-49ea-9984-05c4bf8604f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ee6e0c-501a-434f-ae3d-d5629647dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/anaconda3/lib/python3.12/site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /opt/anaconda3/lib/python3.12/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.9->textblob) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a22f7b4-b0ad-4c31-b68e-13817c66ab8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>polarity_tb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>D’Elmar Zaya</td>\n",
       "      <td>-0.9919</td>\n",
       "      <td>-0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Bis Hierhin</td>\n",
       "      <td>-0.9953</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Losin’ Streak</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Love in a Bottle</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.196984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>VOX POPULI</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.096463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist             title  vader_compound  polarity_tb\n",
       "0             D’Elmar Zaya         -0.9919    -0.041667\n",
       "1              Bis Hierhin         -0.9953     0.200000\n",
       "2            Losin’ Streak          0.9594     0.068500\n",
       "3         Love in a Bottle          0.9941     0.196984\n",
       "4               VOX POPULI          0.9943     0.096463"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis (VADER + TextBlob)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def compute_sentiments(text):\n",
    "    if not text: return {'vader_compound':0.0,'polarity_tb':0.0,'subjectivity_tb':0.0}\n",
    "    v = analyzer.polarity_scores(text)\n",
    "    tb = TextBlob(text)\n",
    "    return {'vader_compound': v['compound'], 'polarity_tb': tb.sentiment.polarity, 'subjectivity_tb': tb.sentiment.subjectivity}\n",
    "\n",
    "sentiments = songs_df['lyrics'].apply(compute_sentiments).apply(pd.Series)\n",
    "songs_df = pd.concat([songs_df, sentiments], axis=1)\n",
    "songs_df[['artist','title','vader_compound','polarity_tb']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ce2274a-4eb3-4b3a-9653-1a7631ef0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topics:\n",
      "[(0, '0.044*\"vox\" + 0.027*\"spoken\" + 0.023*\"crowd\" + 0.015*\"got\" + 0.013*\"hell\"'), (1, '0.002*\"er\" + 0.002*\"die\" + 0.002*\"der\" + 0.002*\"bi\" + 0.002*\"da\"'), (2, '0.026*\"der\" + 0.022*\"die\" + 0.012*\"mir\" + 0.012*\"wieder\" + 0.012*\"auf\"'), (3, '0.042*\"bottle\" + 0.037*\"love\" + 0.032*\"la\" + 0.019*\"husk\" + 0.016*\"another\"'), (4, '0.035*\"er\" + 0.020*\"die\" + 0.018*\"bi\" + 0.015*\"sie\" + 0.013*\"da\"')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>D’Elmar Zaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Bis Hierhin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Losin’ Streak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Love in a Bottle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>VOX POPULI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist             title  cluster\n",
       "0             D’Elmar Zaya        0\n",
       "1              Bis Hierhin        0\n",
       "2            Losin’ Streak        1\n",
       "3         Love in a Bottle        1\n",
       "4               VOX POPULI        1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic modeling (LDA) and clustering (TF-IDF + KMeans)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "texts = [doc.split() for doc in songs_df['clean_lyrics'] if doc]\n",
    "if texts:\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=min(5, max(1, len(dictionary)//10)), passes=10)\n",
    "    print('LDA topics:'); print(lda.print_topics(num_words=5))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(songs_df['clean_lyrics'])\n",
    "svd = TruncatedSVD(n_components=min(50, X.shape[1]-1 if X.shape[1]>1 else 1))\n",
    "X_reduced = svd.fit_transform(X)\n",
    "k = min(5, max(1, len(songs_df)//2))\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "songs_df['cluster'] = km.fit_predict(X_reduced)\n",
    "songs_df[['artist','title','cluster']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d27d21c-af3d-4565-bb9a-cc8111d4a282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'title', 'lyrics', 'url', 'clean_lyrics', 'vader_compound',\n",
       "       'polarity_tb', 'subjectivity_tb', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96755c8-c9a3-4920-815d-0bbcea78c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lyric length feature if missing\n",
    "if 'lyric_len' not in songs_df.columns:\n",
    "    songs_df['lyric_len'] = songs_df['clean_lyrics'].apply(lambda t: len(str(t).split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dcc85d2-fb15-4584-87bb-b9ddc35a77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56acdd3e-6c7f-4bb4-b0f3-31c70974ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df['popularity'] = (songs_df['lyric_len'] * 0.01 + (songs_df['vader_compound'] + 1) * 0.5) + np.random.normal(0, 0.1, len(songs_df))\n",
    "songs_df['popular_label'] = (songs_df['popularity'] > songs_df['popularity'].median()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47c5f978-3367-4a85-8421-062b9e5b6b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "# To fetch Spotify URLs, install spotipy and set env vars SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET\n",
      "# Uncomment and run after installing spotipy:\n",
      "# import spotipy\n",
      "# from spotipy.oauth2 import SpotifyClientCredentials\n",
      "# client_id = os.getenv('SPOTIFY_CLIENT_ID'); client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
      "# if not client_id or not client_secret: raise ValueError('Set SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET')\n",
      "# sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
      "# def spotify_search_track(artist, title):\n",
      "#     q = f\"track:{title} artist:{artist}\"\n",
      "#     res = sp.search(q, type='track', limit=1)\n",
      "#     items = res.get('tracks', {}).get('items', [])\n",
      "#     if items: return items[0]['external_urls']['spotify'], items[0]['popularity'], items[0]['id']\n",
      "#     return None, None, None\n",
      "# songs_df['spotify_url'], songs_df['spotify_popularity'], songs_df['spotify_id'] = zip(*songs_df.apply(lambda r: spotify_search_track(r['artist'], r['title']), axis=1))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Popularity prediction (proxy popularity + classification)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "songs_df['popularity'] = (songs_df['lyric_len'] * 0.01 + (songs_df['vader_compound'] + 1) * 0.5) + np.random.normal(0, 0.1, len(songs_df))\n",
    "songs_df['popular_label'] = (songs_df['popularity'] > songs_df['popularity'].median()).astype(int)\n",
    "\n",
    "features = X_reduced\n",
    "labels = songs_df['popular_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "clf_lr = LogisticRegression(max_iter=500)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "\n",
    "print('Logistic Regression:\\n', classification_report(y_test, y_pred_lr))\n",
    "print('Random Forest:\\n', classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Spotify lookup (optional)\n",
    "spotify_template = \"\"\"# To fetch Spotify URLs, install spotipy and set env vars SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET\n",
    "# Uncomment and run after installing spotipy:\n",
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "# client_id = os.getenv('SPOTIFY_CLIENT_ID'); client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "# if not client_id or not client_secret: raise ValueError('Set SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET')\n",
    "# sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
    "# def spotify_search_track(artist, title):\n",
    "#     q = f\"track:{title} artist:{artist}\"\n",
    "#     res = sp.search(q, type='track', limit=1)\n",
    "#     items = res.get('tracks', {}).get('items', [])\n",
    "#     if items: return items[0]['external_urls']['spotify'], items[0]['popularity'], items[0]['id']\n",
    "#     return None, None, None\n",
    "# songs_df['spotify_url'], songs_df['spotify_popularity'], songs_df['spotify_id'] = zip(*songs_df.apply(lambda r: spotify_search_track(r['artist'], r['title']), axis=1))\n",
    "\"\"\"\n",
    "print(spotify_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5a7b7ae-1ca0-472f-82dd-af097551ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snscrape not available or failed: No module named 'snscrape'\n"
     ]
    }
   ],
   "source": [
    "# Social media scraping template (snscrape)\n",
    "# Requires: pip install snscrape\n",
    "try:\n",
    "    import snscrape.modules.twitter as sntwitter\n",
    "    social_samples = []\n",
    "    for _, row in songs_df.iterrows():\n",
    "        q = f'\"{row.title}\" {row.artist} -filter:retweets'\n",
    "        tweets = []\n",
    "        for i, t in enumerate(sntwitter.TwitterSearchScraper(q).get_items()):\n",
    "            if i >= 50: break\n",
    "            tweets.append({'date': t.date, 'id': t.id, 'user': t.user.username, 'content': t.content})\n",
    "        if tweets:\n",
    "            df_t = pd.DataFrame(tweets)\n",
    "            df_t['vader'] = df_t['content'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "            social_samples.append({'artist': row.artist, 'title': row.title, 'tweets': df_t})\n",
    "    print('Fetched social samples for', len(social_samples))\n",
    "except Exception as e:\n",
    "    print('snscrape not available or failed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1de7a924-ddba-4d4d-97d5-6fd78c4d05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No social graph built.\n"
     ]
    }
   ],
   "source": [
    "# Social graph (co-mention graph)\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "try:\n",
    "    for sample in social_samples:\n",
    "        df_t = sample['tweets']\n",
    "        for _, t in df_t.iterrows():\n",
    "            user = t['user']; content = t['content']\n",
    "            mentions = [w[1:] for w in content.split() if w.startswith('@')]\n",
    "            G.add_node(user)\n",
    "            for m in mentions:\n",
    "                G.add_node(m)\n",
    "                if G.has_edge(user, m):\n",
    "                    G[user][m]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(user, m, weight=1)\n",
    "    print('Graph:', G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges')\n",
    "except Exception:\n",
    "    print('No social graph built.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1a7763c-5d04-428f-ac13-1f579749c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deltalake in /opt/anaconda3/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: arro3-core>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from deltalake) (0.6.5)\n",
      "Requirement already satisfied: deprecated>=1.2.18 in /opt/anaconda3/lib/python3.12/site-packages (from deltalake) (1.3.1)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from deprecated>=1.2.18->deltalake) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install deltalake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9b69ffb-074f-40ba-b505-7b82b8000418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>url</th>\n",
       "      <th>clean_lyrics</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>polarity_tb</th>\n",
       "      <th>subjectivity_tb</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lyric_len</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>D’Elmar Zaya</td>\n",
       "      <td>3 Contributors\\nD’Elmar Zaya Lyrics\\n[Songtext...</td>\n",
       "      <td>https://genius.com/Sadiq-delmar-zaya-lyrics</td>\n",
       "      <td>contributor elmar zaya lyric songtext zu zaya ...</td>\n",
       "      <td>-0.9919</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>3.812166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Bis Hierhin</td>\n",
       "      <td>1 Contributor\\nBis Hierhin Lyrics\\n[Songtext z...</td>\n",
       "      <td>https://genius.com/Kaisa-natron-bis-hierhin-ly...</td>\n",
       "      <td>contributor bi hierhin lyric songtext zu bi hi...</td>\n",
       "      <td>-0.9953</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>3.216258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Losin’ Streak</td>\n",
       "      <td>14 Contributors\\nTranslations\\nPortuguês\\nItal...</td>\n",
       "      <td>https://genius.com/Blake-roman-sam-haft-and-an...</td>\n",
       "      <td>contributor translation português italiano los...</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1.815955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Love in a Bottle</td>\n",
       "      <td>15 Contributors\\nTranslations\\nItaliano\\nLove ...</td>\n",
       "      <td>https://genius.com/Keith-david-lilli-cooper-ki...</td>\n",
       "      <td>contributor translation italiano love bottle l...</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.196984</td>\n",
       "      <td>0.491825</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>2.599820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>VOX POPULI</td>\n",
       "      <td>27 Contributors\\nTranslations\\nItaliano\\nVOX P...</td>\n",
       "      <td>https://genius.com/Jeremy-jordan-christian-bor...</td>\n",
       "      <td>contributor translation italiano vox populi ly...</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.096463</td>\n",
       "      <td>0.584596</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>4.404194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist             title                                             lyrics  \\\n",
       "0             D’Elmar Zaya  3 Contributors\\nD’Elmar Zaya Lyrics\\n[Songtext...   \n",
       "1              Bis Hierhin  1 Contributor\\nBis Hierhin Lyrics\\n[Songtext z...   \n",
       "2            Losin’ Streak  14 Contributors\\nTranslations\\nPortuguês\\nItal...   \n",
       "3         Love in a Bottle  15 Contributors\\nTranslations\\nItaliano\\nLove ...   \n",
       "4               VOX POPULI  27 Contributors\\nTranslations\\nItaliano\\nVOX P...   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://genius.com/Sadiq-delmar-zaya-lyrics   \n",
       "1  https://genius.com/Kaisa-natron-bis-hierhin-ly...   \n",
       "2  https://genius.com/Blake-roman-sam-haft-and-an...   \n",
       "3  https://genius.com/Keith-david-lilli-cooper-ki...   \n",
       "4  https://genius.com/Jeremy-jordan-christian-bor...   \n",
       "\n",
       "                                        clean_lyrics  vader_compound  \\\n",
       "0  contributor elmar zaya lyric songtext zu zaya ...         -0.9919   \n",
       "1  contributor bi hierhin lyric songtext zu bi hi...         -0.9953   \n",
       "2  contributor translation português italiano los...          0.9594   \n",
       "3  contributor translation italiano love bottle l...          0.9941   \n",
       "4  contributor translation italiano vox populi ly...          0.9943   \n",
       "\n",
       "   polarity_tb  subjectivity_tb  cluster  lyric_len  popularity  popular_label  \n",
       "0    -0.041667         0.141667        0        376    3.812166              1  \n",
       "1     0.200000         0.600000        0        327    3.216258              0  \n",
       "2     0.068500         0.522000        1         81    1.815955              0  \n",
       "3     0.196984         0.491825        1        166    2.599820              0  \n",
       "4     0.096463         0.584596        1        342    4.404194              1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deltalake import DeltaTable, write_deltalake\n",
    "import pandas as pd\n",
    "\n",
    "# Write your dataframe to Delta format\n",
    "write_deltalake(\"lyrics_lens_delta\", songs_df)\n",
    "\n",
    "# Read it back\n",
    "dt = DeltaTable(\"lyrics_lens_delta\")\n",
    "df_reload = dt.to_pandas()\n",
    "\n",
    "print(\"Rows:\", len(df_reload))\n",
    "df_reload.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5104cfa-0c13-415e-bf04-93a769ef8740",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'read_deltalake' from 'deltalake' (/opt/anaconda3/lib/python3.12/site-packages/deltalake/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save songs_df to Delta format (deltalake)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeltalake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_deltalake, read_deltalake\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m songs_write_df \u001b[38;5;241m=\u001b[39m songs_df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'read_deltalake' from 'deltalake' (/opt/anaconda3/lib/python3.12/site-packages/deltalake/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Save songs_df to Delta format (deltalake)\n",
    "from deltalake import write_deltalake, read_deltalake\n",
    "import json\n",
    "songs_write_df = songs_df.copy()\n",
    "songs_write_df['lyrics'] = songs_write_df['lyrics'].astype(str)\n",
    "songs_write_df['clean_lyrics'] = songs_write_df['clean_lyrics'].astype(str)\n",
    "songs_write_df['nrc_emotions'] = songs_write_df.get('nrc_emotions', pd.Series([{}]*len(songs_write_df))).astype(str)\n",
    "songs_delta_path = os.path.join(DELTA_DIR, 'songs.delta')\n",
    "write_deltalake(songs_delta_path, songs_write_df, mode='overwrite')\n",
    "print('Wrote songs delta to', songs_delta_path)\n",
    "df_read = read_deltalake(songs_delta_path)\n",
    "print('Read back rows:', len(df_read))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bf7f829-af5e-4128-8063-8fc5a798c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to ./lyrics_lens_data/models\n"
     ]
    }
   ],
   "source": [
    "# Save trained models (joblib)\n",
    "import joblib, os\n",
    "models_dir = os.path.join(DATA_DIR, 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "joblib.dump(clf_rf, os.path.join(models_dir, 'rf_popularity.pkl'))\n",
    "joblib.dump(clf_lr, os.path.join(models_dir, 'lr_popularity.pkl'))\n",
    "print('Saved models to', models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c26e149-a432-49c7-b81a-6eced9a796e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57d34dc4-5ae5-4920-8c18-adc2c7724611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                     Type                          Data/Info\n",
      "--------------------------------------------------------------------\n",
      "BeautifulSoup                type                          <class 'bs4.BeautifulSoup'>\n",
      "DATA_DIR                     str                           ./lyrics_lens_data\n",
      "DELTA_DIR                    str                           ./lyrics_lens_data/delta_tables\n",
      "DeltaTable                   type                          <class 'deltalake.table.DeltaTable'>\n",
      "G                            Graph                         Graph with 0 nodes and 0 edges\n",
      "KMeans                       ABCMeta                       <class 'sklearn.cluster._kmeans.KMeans'>\n",
      "LogisticRegression           type                          <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
      "MAX_SCRAPED_RECORDS          int                           100\n",
      "MultiLabelBinarizer          type                          <class 'sklearn.preproces<...>bel.MultiLabelBinarizer'>\n",
      "REQUEST_SLEEP                tuple                         n=2\n",
      "RandomForestClassifier       ABCMeta                       <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
      "SEED_QUERIES                 list                          n=8\n",
      "STOPWORDS                    set                           {'the', \"i'm\", 'out', 'wh<...>couldn't\", 'do', \"she's\"}\n",
      "SentimentIntensityAnalyzer   type                          <class 'vaderSentiment.va<...>timentIntensityAnalyzer'>\n",
      "TextBlob                     type                          <class 'textblob.blob.TextBlob'>\n",
      "TfidfVectorizer              type                          <class 'sklearn.feature_e<...>on.text.TfidfVectorizer'>\n",
      "TruncatedSVD                 type                          <class 'sklearn.decomposi<...>ncated_svd.TruncatedSVD'>\n",
      "WordNetLemmatizer            type                          <class 'nltk.stem.wordnet.WordNetLemmatizer'>\n",
      "X                            csr_matrix                      (0, 81)\t0.0153173018500<...> 474)\t0.02904411714430451\n",
      "X_reduced                    ndarray                       5x5: 25 elems, type `float64`, 200 bytes\n",
      "X_test                       ndarray                       2x5: 10 elems, type `float64`, 80 bytes\n",
      "X_train                      ndarray                       3x5: 15 elems, type `float64`, 120 bytes\n",
      "accuracy_score               function                      <function accuracy_score at 0x143d48f40>\n",
      "analyzer                     SentimentIntensityAnalyzer    <vaderSentiment.vaderSent<...>er object at 0x145e92900>\n",
      "classification_report        function                      <function classification_report at 0x143d4a3e0>\n",
      "clf_lr                       LogisticRegression            LogisticRegression(max_iter=500)\n",
      "clf_rf                       RandomForestClassifier        RandomForestClassifier(random_state=42)\n",
      "collected                    list                          n=5\n",
      "compute_sentiments           function                      <function compute_sentiments at 0x1770d8720>\n",
      "confusion_matrix             function                      <function confusion_matrix at 0x143d49080>\n",
      "corpora                      module                        <module 'gensim.corpora' <...>sim/corpora/__init__.py'>\n",
      "corpus                       list                          n=5\n",
      "cosine_similarity            function                      <function cosine_similarity at 0x143b3b880>\n",
      "dataframe_columns            function                      <function dataframe_columns at 0x31631d120>\n",
      "dataframe_hash               function                      <function dataframe_hash at 0x300d4bce0>\n",
      "df_reload                    DataFrame                       artist             titl<...>4.404194              1  \n",
      "dictionary                   Dictionary                    Dictionary<681 unique tok<...>', 'auf', 'baccarat']...>\n",
      "dt                           DeltaTable                    DeltaTable()\n",
      "dtypes_str                   function                      <function dtypes_str at 0x31631df80>\n",
      "features                     ndarray                       5x5: 25 elems, type `float64`, 200 bytes\n",
      "genius_search_results        function                      <function genius_search_results at 0x1328d34c0>\n",
      "gensim                       module                        <module 'gensim' from '/o<...>ages/gensim/__init__.py'>\n",
      "get_dataframes               function                      <function get_dataframes at 0x300d4be20>\n",
      "get_request_simple           function                      <function get_request_simple at 0x132d25a80>\n",
      "getpass                      module                        <module 'getpass' from '/<...>b/python3.12/getpass.py'>\n",
      "hashlib                      module                        <module 'hashlib' from '/<...>b/python3.12/hashlib.py'>\n",
      "import_pandas_safely         function                      <function import_pandas_safely at 0x31631e160>\n",
      "is_data_frame                function                      <function is_data_frame at 0x31631d3a0>\n",
      "joblib                       module                        <module 'joblib' from '/o<...>ages/joblib/__init__.py'>\n",
      "json                         module                        <module 'json' from '/opt<...>on3.12/json/__init__.py'>\n",
      "k                            int                           2\n",
      "km                           KMeans                        KMeans(n_clusters=2, random_state=42)\n",
      "labels                       ndarray                       5: 5 elems, type `int64`, 40 bytes\n",
      "lda                          LdaModel                      LdaModel<num_terms=681, n<...>ecay=0.5, chunksize=2000>\n",
      "lemmatizer                   WordNetLemmatizer             <WordNetLemmatizer>\n",
      "models_dir                   str                           ./lyrics_lens_data/models\n",
      "nltk                         module                        <module 'nltk' from '/opt<...>ckages/nltk/__init__.py'>\n",
      "np                           module                        <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "nx                           module                        <module 'networkx' from '<...>es/networkx/__init__.py'>\n",
      "os                           module                        <module 'os' (frozen)>\n",
      "pd                           module                        <module 'pandas' from '/o<...>ages/pandas/__init__.py'>\n",
      "plt                          module                        <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "preprocess_text              function                      <function preprocess_text at 0x1328d32e0>\n",
      "q                            str                           Bruno Mars Uptown Funk\n",
      "random                       module                        <module 'random' from '/o<...>ib/python3.12/random.py'>\n",
      "requests                     module                        <module 'requests' from '<...>es/requests/__init__.py'>\n",
      "results                      list                          n=5\n",
      "roc_auc_score                function                      <function roc_auc_score at 0x143d78540>\n",
      "roc_curve                    function                      <function roc_curve at 0x143d78900>\n",
      "scrape_genius_song           function                      <function scrape_genius_song at 0x1328d3420>\n",
      "sentiments                   DataFrame                        vader_compound  polari<...>0.096463         0.584596\n",
      "silhouette_score             function                      <function silhouette_score at 0x143d48400>\n",
      "sns                          module                        <module 'seaborn' from '/<...>ges/seaborn/__init__.py'>\n",
      "song                         dict                          n=4\n",
      "songs_df                     DataFrame                       artist             titl<...>4.404194              1  \n",
      "spotify_template             str                           # To fetch Spotify URLs, <...>, r['title']), axis=1))\\n\n",
      "stopwords                    WordListCorpusReader          <WordListCorpusReader in <...>_data/corpora/stopwords'>\n",
      "svd                          TruncatedSVD                  TruncatedSVD(n_components=50)\n",
      "texts                        list                          n=5\n",
      "time                         module                        <module 'time' (built-in)>\n",
      "train_test_split             function                      <function train_test_split at 0x143db8860>\n",
      "url                          str                           https://genius.com/Jeremy<...>derberg-vox-populi-lyrics\n",
      "vectorizer                   TfidfVectorizer               TfidfVectorizer(max_features=1000)\n",
      "visited                      set                           {'https://genius.com/Jere<...>adiq-delmar-zaya-lyrics'}\n",
      "write_deltalake              function                      <function write_deltalake at 0x304ff42c0>\n",
      "y_pred_lr                    ndarray                       2: 2 elems, type `int64`, 16 bytes\n",
      "y_pred_rf                    ndarray                       2: 2 elems, type `int64`, 16 bytes\n",
      "y_test                       ndarray                       2: 2 elems, type `int64`, 16 bytes\n",
      "y_train                      ndarray                       3: 3 elems, type `int64`, 24 bytes\n"
     ]
    }
   ],
   "source": [
    "%whos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25aeedb6-99d3-4ca2-bf2d-7123b7f82f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 TEST RESULTS: PREDICTING SONG POPULARITY\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- TEST LOGISTIC REGRESSION & RANDOM FOREST ---\n",
    "\n",
    "print(\"📌 TEST RESULTS: PREDICTING SONG POPULARITY\")\n",
    "print(\"\\n--- Logistic Regression ---\")\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\n--- Random Forest ---\")\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1220f86-3673-4133-b68e-dc2032bbd507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 KMEANS CLUSTERING TEST\n",
      "Cluster Labels: [1 0 0 0 1]\n",
      "Silhouette Score: -0.02078736038327999\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 KMEANS CLUSTERING TEST\")\n",
    "print(\"Cluster Labels:\", labels)\n",
    "print(\"Silhouette Score:\", silhouette_score(X_reduced, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b90f3b2-a901-4470-8996-782c17c9161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 TOPIC MODELING TEST (LDA)\n",
      "\n",
      "Topic 4: 0.035*\"er\" + 0.020*\"die\" + 0.018*\"bi\" + 0.015*\"sie\" + 0.013*\"da\" + 0.013*\"hierhin\" + 0.011*\"gut\" + 0.011*\"lief\" + 0.011*\"hier\" + 0.011*\"um\"\n",
      "\n",
      "Topic 0: 0.044*\"vox\" + 0.027*\"spoken\" + 0.023*\"crowd\" + 0.015*\"got\" + 0.013*\"hell\" + 0.009*\"populi\" + 0.009*\"yeah\" + 0.009*\"could\" + 0.009*\"new\" + 0.009*\"let\"\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 TOPIC MODELING TEST (LDA)\")\n",
    "\n",
    "for idx, topic in lda.print_topics(num_topics=2, num_words=10):\n",
    "    print(f\"\\nTopic {idx}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55de2de5-b53a-4ff1-a9d5-f6e43822d969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 SENTIMENT TEST (VADER + TextBlob)\n",
      "\n",
      "Sample lyric: 3 Contributors\n",
      "D’Elmar Zaya Lyrics\n",
      "[Songtext zu „D'Elmar Zaya“]\n",
      "[Intro]\n",
      "Überall, wo wir hingeh'n, hinterlassen wir Spuren\n",
      "Ob es deine DNA ist, deine Fingerabdrücke oder dein Geruch\n",
      "Die Geruchsspur'n n ...\n",
      "\n",
      "VADER: {'neg': 0.096, 'neu': 0.896, 'pos': 0.008, 'compound': -0.9919}\n",
      "TextBlob: Sentiment(polarity=-0.041666666666666664, subjectivity=0.14166666666666666)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 SENTIMENT TEST (VADER + TextBlob)\\n\")\n",
    "\n",
    "sample_text = songs_df['lyrics'].iloc[0]\n",
    "\n",
    "vader_result = analyzer.polarity_scores(sample_text)\n",
    "textblob_result = TextBlob(sample_text).sentiment\n",
    "\n",
    "print(\"Sample lyric:\", sample_text[:200], \"...\\n\")\n",
    "print(\"VADER:\", vader_result)\n",
    "print(\"TextBlob:\", textblob_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f22256dc-67d3-45c8-bd75-1ea1d5094b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 FULL PIPELINE TEST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clean_lyric': 'feel happy alive dancing golden light',\n",
       " 'logistic_prediction': 0,\n",
       " 'random_forest_prediction': 0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def full_pipeline_predict(lyric):\n",
    "    clean = preprocess_text(lyric)\n",
    "    vec = vectorizer.transform([clean])\n",
    "    reduced = svd.transform(vec)\n",
    "    \n",
    "    pred_lr = clf_lr.predict(reduced)[0]\n",
    "    pred_rf = clf_rf.predict(reduced)[0]\n",
    "\n",
    "    return {\n",
    "        \"clean_lyric\": clean,\n",
    "        \"logistic_prediction\": pred_lr,\n",
    "        \"random_forest_prediction\": pred_rf\n",
    "    }\n",
    "\n",
    "print(\"📌 FULL PIPELINE TEST\")\n",
    "test_output = full_pipeline_predict(\"I feel happy and alive, dancing in the golden light\")\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "febf1b34-b855-426b-ab2b-f2867f38a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta Table Loaded Successfully.\n",
      "  artist             title                                             lyrics  \\\n",
      "0             D’Elmar Zaya  3 Contributors\\nD’Elmar Zaya Lyrics\\n[Songtext...   \n",
      "1              Bis Hierhin  1 Contributor\\nBis Hierhin Lyrics\\n[Songtext z...   \n",
      "2            Losin’ Streak  14 Contributors\\nTranslations\\nPortuguês\\nItal...   \n",
      "3         Love in a Bottle  15 Contributors\\nTranslations\\nItaliano\\nLove ...   \n",
      "4               VOX POPULI  27 Contributors\\nTranslations\\nItaliano\\nVOX P...   \n",
      "\n",
      "                                                 url  \\\n",
      "0        https://genius.com/Sadiq-delmar-zaya-lyrics   \n",
      "1  https://genius.com/Kaisa-natron-bis-hierhin-ly...   \n",
      "2  https://genius.com/Blake-roman-sam-haft-and-an...   \n",
      "3  https://genius.com/Keith-david-lilli-cooper-ki...   \n",
      "4  https://genius.com/Jeremy-jordan-christian-bor...   \n",
      "\n",
      "                                        clean_lyrics  vader_compound  \\\n",
      "0  contributor elmar zaya lyric songtext zu zaya ...         -0.9919   \n",
      "1  contributor bi hierhin lyric songtext zu bi hi...         -0.9953   \n",
      "2  contributor translation português italiano los...          0.9594   \n",
      "3  contributor translation italiano love bottle l...          0.9941   \n",
      "4  contributor translation italiano vox populi ly...          0.9943   \n",
      "\n",
      "   polarity_tb  subjectivity_tb  cluster  lyric_len  popularity  popular_label  \n",
      "0    -0.041667         0.141667        0        376    3.812166              1  \n",
      "1     0.200000         0.600000        0        327    3.216258              0  \n",
      "2     0.068500         0.522000        1         81    1.815955              0  \n",
      "3     0.196984         0.491825        1        166    2.599820              0  \n",
      "4     0.096463         0.584596        1        342    4.404194              1  \n"
     ]
    }
   ],
   "source": [
    "dt = DeltaTable(\"lyrics_lens_delta\")\n",
    "df_reload = dt.to_pandas()\n",
    "\n",
    "print(\"Delta Table Loaded Successfully.\")\n",
    "print(df_reload.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2719d9-0308-4a73-8eb9-039e754eab55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
